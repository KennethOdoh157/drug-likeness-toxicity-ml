{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "595d45a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to Python path for src imports\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Custom functions\n",
    "from src.models import get_random_forest\n",
    "from src.evaluation import (\n",
    "    compute_roc_auc,\n",
    "    plot_roc_curve,\n",
    "    compute_classification_metrics,\n",
    "    plot_confusion_matrix\n",
    ")\n",
    "\n",
    "# Directories\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "RESULTS_FIGURES = RESULTS_DIR / \"figures\"\n",
    "RESULTS_METRICS = RESULTS_DIR / \"metrics\"\n",
    "\n",
    "# Create folders if missing\n",
    "RESULTS_FIGURES.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_METRICS.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeae56fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial descriptor shape: (3074, 217)\n",
      "Total NaNs in descriptors: 442\n",
      "Final X shape: (3074, 217)\n",
      "Any NaNs left in X? False\n"
     ]
    }
   ],
   "source": [
    "# Load descriptor features\n",
    "X_desc = pd.read_csv(DATA_PROCESSED / \"tox21_descriptors.csv\")\n",
    "\n",
    "# Drop non-feature columns if they exist\n",
    "X_desc = X_desc.drop(columns=[\"smiles\", \"mol_id\"], errors=\"ignore\")\n",
    "\n",
    "# Replace infinite values with NaN\n",
    "X_desc = X_desc.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "print(\"Initial descriptor shape:\", X_desc.shape)\n",
    "print(\"Total NaNs in descriptors:\", X_desc.isna().sum().sum())\n",
    "\n",
    "# Fill remaining NaNs with median (robust for chemical descriptors)\n",
    "X_desc = X_desc.fillna(X_desc.median())\n",
    "\n",
    "# Convert to NumPy array for modeling\n",
    "X = X_desc.values\n",
    "\n",
    "print(\"Final X shape:\", X.shape)\n",
    "print(\"Any NaNs left in X?\", np.isnan(X).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5de7c622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape (assays): (3074, 12)\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned assay labels\n",
    "tox21 = pd.read_csv(DATA_PROCESSED / \"tox21_clean.csv\")\n",
    "\n",
    "# Assay columns\n",
    "ASSAY_COLUMNS = [\n",
    "    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase',\n",
    "    'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma',\n",
    "    'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'\n",
    "]\n",
    "\n",
    "y = tox21[ASSAY_COLUMNS]\n",
    "\n",
    "print(\"y shape (assays):\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e93f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(str(PROJECT_ROOT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "838e1f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model for NR-AR\n",
      "\n",
      "Evaluating model for NR-AR-LBD\n",
      "\n",
      "Evaluating model for NR-AhR\n",
      "\n",
      "Evaluating model for NR-Aromatase\n",
      "\n",
      "Evaluating model for NR-ER\n",
      "\n",
      "Evaluating model for NR-ER-LBD\n",
      "\n",
      "Evaluating model for NR-PPAR-gamma\n",
      "\n",
      "Evaluating model for SR-ARE\n",
      "\n",
      "Evaluating model for SR-ATAD5\n",
      "\n",
      "Evaluating model for SR-HSE\n",
      "\n",
      "Evaluating model for SR-MMP\n",
      "\n",
      "Evaluating model for SR-p53\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "metrics_list = []\n",
    "\n",
    "for target in y.columns:\n",
    "    print(f\"\\nEvaluating model for {target}\")\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y[target],\n",
    "        test_size=0.2,\n",
    "        stratify=y[target],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Initialize class-weighted RandomForest\n",
    "    model = get_random_forest(class_weight=\"balanced\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities\n",
    "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # ROC-AUC\n",
    "    roc_auc = compute_roc_auc(y_test, y_pred_prob)\n",
    "\n",
    "    # Optimize threshold based on F1-score\n",
    "    thresholds = np.linspace(0, 1, 101)\n",
    "    f1_scores = [f1_score(y_test, (y_pred_prob >= t).astype(int), zero_division=0) for t in thresholds]\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_idx]\n",
    "    y_pred = (y_pred_prob >= best_threshold).astype(int)\n",
    "\n",
    "    # Compute metrics\n",
    "    precision, recall, f1 = compute_classification_metrics(y_test, y_pred)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plot_roc_curve(\n",
    "        y_test,\n",
    "        y_pred_prob,\n",
    "        title=f\"ROC Curve — {target}\",\n",
    "        save_path=RESULTS_FIGURES / f\"roc_{target}.png\"\n",
    "    )\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        title=f\"Confusion Matrix — {target}\",\n",
    "        save_path=RESULTS_FIGURES / f\"cm_{target}.png\"\n",
    "    )\n",
    "\n",
    "    # Save results\n",
    "    metrics_list.append({\n",
    "        \"assay\": target,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"best_threshold\": best_threshold\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cda4b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assay</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>best_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR-AR</td>\n",
       "      <td>0.665077</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR-AR-LBD</td>\n",
       "      <td>0.642505</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR-AhR</td>\n",
       "      <td>0.844703</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR-Aromatase</td>\n",
       "      <td>0.756171</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR-ER</td>\n",
       "      <td>0.637566</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.273684</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NR-ER-LBD</td>\n",
       "      <td>0.528750</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NR-PPAR-gamma</td>\n",
       "      <td>0.884918</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SR-ARE</td>\n",
       "      <td>0.707131</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SR-ATAD5</td>\n",
       "      <td>0.557096</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SR-HSE</td>\n",
       "      <td>0.632397</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SR-MMP</td>\n",
       "      <td>0.933652</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SR-p53</td>\n",
       "      <td>0.809113</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            assay   roc_auc  precision    recall  f1_score  best_threshold\n",
       "0           NR-AR  0.665077   0.400000  0.500000  0.444444            0.12\n",
       "1       NR-AR-LBD  0.642505   0.666667  0.285714  0.400000            0.23\n",
       "2          NR-AhR  0.844703   0.263158  0.483871  0.340909            0.14\n",
       "3    NR-Aromatase  0.756171   0.200000  0.181818  0.190476            0.15\n",
       "4           NR-ER  0.637566   0.276596  0.270833  0.273684            0.17\n",
       "5       NR-ER-LBD  0.528750   0.400000  0.153846  0.222222            0.30\n",
       "6   NR-PPAR-gamma  0.884918   0.500000  0.200000  0.285714            0.17\n",
       "7          SR-ARE  0.707131   0.342857  0.307692  0.324324            0.16\n",
       "8        SR-ATAD5  0.557096   0.003252  1.000000  0.006483            0.00\n",
       "9          SR-HSE  0.632397   0.285714  0.200000  0.235294            0.13\n",
       "10         SR-MMP  0.933652   0.866667  0.464286  0.604651            0.28\n",
       "11         SR-p53  0.809113   0.666667  0.333333  0.444444            0.12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert metrics list to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "# Save to CSV\n",
    "metrics_df.to_csv(RESULTS_METRICS / \"model_metrics.csv\", index=False)\n",
    "\n",
    "# Display final metrics\n",
    "metrics_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cheminfo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
